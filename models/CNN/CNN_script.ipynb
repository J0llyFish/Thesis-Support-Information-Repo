{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vjy66vZS5Va",
        "outputId": "36811d3b-5512-496c-fb99-256ae727448b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/My Drive\n",
            "/gdrive/My Drive/ML_Data/MM/INCHI\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:2539: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
            "  output = genfromtxt(fname, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as kr\n",
        "from tensorflow import keras as keras\n",
        "import os , scipy.io\n",
        "#minors\n",
        "import math\n",
        "import time\n",
        "import scipy\n",
        "import random\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D ,Conv1D\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# plot related\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.figure import Figure\n",
        "from tensorflow.keras import backend as K\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "#networking related\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# load dataset from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# linux operation\n",
        "%cd /gdrive/My Drive/\n",
        "%cd ML_Data/MM/INCHI/\n",
        "\n",
        "split_ratio = 0.9 # train data ratio\n",
        "\n",
        "# load data\n",
        "X_data = np.genfromtxt('target.dat', delimiter=',', skip_header = 1)\n",
        "Y_data = np.genfromtxt('label.dat', delimiter=',', skip_header = 1,)\n",
        "name_list = np.recfromcsv('index.dat')\n",
        "\n",
        "X_data = 1-X_data\n",
        "Y_data = 1-Y_data\n",
        "\n",
        "X_data = X_data.reshape(len(X_data),len(X_data[1]),1)\n",
        "Y_data = Y_data.reshape(len(Y_data),len(Y_data[1]))\n",
        "\n",
        "# split data into train and test\n",
        "x_train = X_data[0:math.floor(split_ratio*len(X_data))]\n",
        "x_test = X_data[math.floor(split_ratio*len(X_data)):len(X_data)]\n",
        "\n",
        "y_train = Y_data[0:math.floor(split_ratio*len(Y_data))]\n",
        "y_test = Y_data[math.floor(split_ratio*len(Y_data)):len(Y_data)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuI7kUOJTH3R"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential(name=\"model_conv1D\")\n",
        "model.add(tf.keras.Input(shape=(len(X_data[1]),1),name='INPUT'))\n",
        "model.add(keras.layers.Conv1D(filters=2, strides=2, kernel_size=2, activation=keras.layers.LeakyReLU(alpha=0.2),))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Dropout(0.4))\n",
        "model.add(keras.layers.Conv1D(filters=4, strides=2, kernel_size=2, activation=keras.layers.LeakyReLU(alpha=0.2),))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Dropout(0.4))\n",
        "model.add(keras.layers.Conv1D(filters=8, strides=2, kernel_size=2, activation=keras.layers.LeakyReLU(alpha=0.2),))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Dropout(0.4))\n",
        "model.add(keras.layers.Conv1D(filters=16, strides=2, kernel_size=2, activation=keras.layers.LeakyReLU(alpha=0.2),))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Dropout(0.4))\n",
        "model.add(keras.layers.Conv1D(filters=32, strides=2, kernel_size=2, activation=keras.layers.LeakyReLU(alpha=0.2),))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Dropout(0.4))\n",
        "model.add(keras.layers.Flatten()) # important\n",
        "model.add(keras.layers.Dense(64, activation=keras.layers.LeakyReLU(alpha=0.2),kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
        "model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
        "model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)))\n",
        "model.add(keras.layers.Reshape((8,  8)))\n",
        "model.add(keras.layers.Conv1DTranspose(32, kernel_size=2, strides=2, padding=\"same\", activation=keras.layers.LeakyReLU(alpha=0.2)))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv1DTranspose(16, kernel_size=2, strides=2, padding=\"same\", activation=keras.layers.LeakyReLU(alpha=0.2)))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv1DTranspose(8, kernel_size=2, strides=2, padding=\"same\", activation=keras.layers.LeakyReLU(alpha=0.2)))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv1DTranspose(4, kernel_size=2, strides=2, padding=\"same\", activation=keras.layers.LeakyReLU(alpha=0.2)))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv1DTranspose(2, kernel_size=2, strides=2, padding=\"same\", activation=keras.layers.LeakyReLU(alpha=0.2)))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(len(Y_data[1]), name=\"Dense_output\"))\n",
        "model.compile(optimizer=\"adam\", loss='mean_absolute_error')\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xbb8EhAWTNh5"
      },
      "outputs": [],
      "source": [
        "print('START!')\n",
        "#start = time.time()\n",
        "# fit with val-set\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience=150, min_delta=0.0005, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(x_train,y_train,batch_size=32,epochs=500,validation_split=0.11)\n",
        "#end = time.time()\n",
        "print('Train End!')\n",
        "los=model.evaluate(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9ZR_-Jfnt3a"
      },
      "outputs": [],
      "source": [
        "# export CSV\n",
        "train_dat = history.history\n",
        "loss_dat = train_dat['loss']\n",
        "val_dat = train_dat['val_loss']\n",
        "offset = 0\n",
        "\n",
        "for i in range(len(loss_dat)):\n",
        "  print(str(i+1+offset)+','+str(loss_dat[i])+','+str(val_dat[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E76BwB5DVVua"
      },
      "source": [
        "## evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpzSGuEEE0uD"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import spearmanr\n",
        "# final evaluation\n",
        "spearsman_list_MM = []\n",
        "spearsman_list_NN = []\n",
        "ans = model.predict(x_test)\n",
        "for i in range(len(x_test)):\n",
        "  correlation, p = spearmanr(ans[i],y_test[i])\n",
        "  spearsman_list_NN.append(correlation)\n",
        "  correlation, p = spearmanr(x_test[i],y_test[i])\n",
        "  spearsman_list_MM.append(correlation)\n",
        "\n",
        "print('Neuron: ',end='')\n",
        "print(sum(spearsman_list_NN)/len(x_test))\n",
        "print('Molecular Mechanics: ',end='')\n",
        "print(sum(spearsman_list_MM)/len(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nBHxvVQvjfM"
      },
      "source": [
        "# Get list of spearsman coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwhEK8U_XT5O"
      },
      "outputs": [],
      "source": [
        "for i in range(len(x_test)):\n",
        "  print(str(i+1)+',',end='')\n",
        "  print(spearsman_list_NN[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A3gKKmQZ9Ol"
      },
      "source": [
        "## Draw IR spectra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLnRS7WBTTJh"
      },
      "outputs": [],
      "source": [
        "def get_spearsman_ir(i):\n",
        "  los=model.evaluate(x_test[i].reshape(1,len(x_test[1]),1),y_test[i].reshape(1,len(x_test[1])))\n",
        "  print('loss : ',end='')\n",
        "  print(los)\n",
        "  ans = model.predict(x_test[i].reshape(1,len(x_test[1]),1))#.reshape(1,len(x_test[1])))\n",
        "  ans = ans.reshape(len(x_test[1]))\n",
        "  from scipy.stats import spearmanr\n",
        "  correlation, p = spearmanr(ans,y_test[i])\n",
        "  print('Correlation:', correlation)\n",
        "  # print('p-value:', p)\n",
        "  return  correlation\n",
        "\n",
        "def get_name(cas):\n",
        "  re = re = requests.get('https://webbook.nist.gov/cgi/cbook.cgi?Name='+str(cas)+'&Units=SI')\n",
        "  soup = BeautifulSoup(re.text, 'html.parser')\n",
        "  check_tag = soup.find(id='Top')\n",
        "  if check_tag and check_tag.get_text() != 'Name Not Found':\n",
        "    return check_tag.text\n",
        "\n",
        "def plotter(plt_list):\n",
        "  plt.rcParams[\"figure.figsize\"] = (15,2.5*len(plt_list))\n",
        "  for i in range(len(plt_list)):\n",
        "    fig =plt.subplot(len(plt_list),1,i+1)\n",
        "    #model validation\n",
        "    #k=randomlist[6]\n",
        "    k = plt_list[i]\n",
        "    ans = model.predict(x_test[k].reshape(1,len(X_data[1]),1))\n",
        "\n",
        "    answer = ans.reshape(len(X_data[1]))\n",
        "    answer=1-answer\n",
        "    range_ir = np.arange(400, 4001, 2)\n",
        "    fig.plot(range_ir, 1-x_test[k],  c='g', label='DB' , linewidth=1.0)\n",
        "    # scipy.signal.savgol_filter(1-Y_data[k],25,7)\n",
        "    fig.plot(range_ir, 1-y_test[k] ,  c='b', label='DB' , linewidth=1.0)\n",
        "    fig.plot(range_ir, answer ,  c='r', label='DB' , linewidth=1.0)\n",
        "    #y_smooth = scipy.signal.savgol_filter((1-Y_data[k]).reshape(3151),window_length=25,polyorder=3,delta=1,)\n",
        "    #fig.plot(range(600, 3751), y_smooth ,  c='r', label='DB' , linewidth=1.0)\n",
        "\n",
        "    fig.invert_xaxis()\n",
        "    fig.grid(True)\n",
        "    #fig.title.set_text(name_list[k+len(x_train)].tostring('c').strip(b'\\x00'))\n",
        "    name_cas = str(name_list[k+len(x_train)].tostring('c').strip(b'\\x00'),encoding='utf-8')\n",
        "    print(name_cas)\n",
        "    get_spearsman_ir(k)\n",
        "    plt.title(get_name(name_cas))\n",
        "    print(get_name(name_cas))\n",
        "    fig.set_ylim([0, 1.2])\n",
        "    #plt.show()\n",
        "\n",
        "\n",
        "#plotter([69,70,71,72])\n",
        "plotter(random.sample(range(len(x_test)),1))\n",
        "# plotter([493,223,207])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Xtr4gBxRTT"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy-tGTj3xXFX"
      },
      "outputs": [],
      "source": [
        "model.save('CNN/CNN_Model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4gWMUz7xdQ-"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwiNIaC3xiB8"
      },
      "outputs": [],
      "source": [
        "model  = tf.keras.models.load_model('CNN/CNN_Model.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
